/**
 * @file ai-service.js
 * @description M√≥dulo respons√°vel pela comunica√ß√£o com a IA do Google (Gemini) para gera√ß√£o autom√°tica de conte√∫do.
 * @module services/aiService
 */

export const aiService = {
    /** * Chave de API obscurecida em Base64 para evitar detec√ß√£o autom√°tica por scrapers simples.
     * Nota: Isso n√£o √© criptografia de seguran√ßa, apenas ofusca√ß√£o.
     * @private
     * @type {string}
     */
    _k: 'QUl6YVN5RGowZ2k5cWVNMkxocFdCWFMzNUNEdHhZUW1PR3JDVzVJ',

    /**
     * Retorna a chave de API decodificada em tempo de execu√ß√£o.
     * @returns {string} A chave da API decodificada ou string vazia se falhar.
     */
    get API_KEY() {
        try {
            return atob(this._k);
        } catch (e) {
            console.error("Erro ao decodificar API Key:", e);
            return "";
        }
    },

    /** * Lista de modelos dispon√≠veis para estrat√©gia de fallback (tentativa e erro).
     * Se o primeiro falhar (ex: rate limit), tenta o pr√≥ximo.
     * @type {Array<{id: string, v: string}>}
     */
    MODELOS: [
        { id: 'gemini-2.5-flash-lite', v: 'v1beta' },
        { id: 'gemini-3-flash-preview', v: 'v1beta' },
        { id: 'gemini-2.5-flash', v: 'v1beta' },
        { id: 'gemini-flash-lite-latest', v: 'v1beta' }
    ],

    /**
     * Pausa a execu√ß√£o por um tempo determinado (√∫til para backoff exponencial).
     * @private
     * @param {number} ms - Milissegundos para esperar.
     * @returns {Promise<void>}
     */
    _esperar: (ms) => new Promise(res => setTimeout(res, ms)),

    /**
     * Gera uma quest√£o in√©dita baseada nos par√¢metros pedag√≥gicos fornecidos.
     * Utiliza uma estrat√©gia de rota√ß√£o de modelos para garantir alta disponibilidade.
     * @async
     * @param {Object} params - Par√¢metros da quest√£o.
     * @param {string} params.materia - Disciplina escolar (ex: Matem√°tica).
     * @param {Object} params.habilidade - Objeto contendo {codigo, descricao} da BNCC.
     * @param {number} params.dificuldade - N√≠vel de dificuldade (1=F√°cil a 3=Dif√≠cil).
     * @param {string} params.tipo - 'multipla' ou 'aberta'.
     * @returns {Promise<Object>} Objeto da quest√£o formatado com enunciado e alternativas/gabarito.
     * @throws {Error} Se todos os modelos falharem.
     */
    async gerarQuestao({ materia, habilidade, dificuldade, tipo }) {
        const diffLabels = ["Aleat√≥ria", "F√°cil", "M√©dia", "Dif√≠cil"];
        
        // Prompt otimizado para gerar JSON puro
        const prompt = `
            Atue como um professor especialista. Crie uma quest√£o in√©dita para a disciplina de ${materia}.
            Baseie-se na habilidade BNCC: ${habilidade.codigo} - ${habilidade.descricao}.
            Dificuldade: ${diffLabels[dificuldade]}.
            Tipo: ${tipo === 'multipla' ? 'M√∫ltipla escolha com 4 ou 5 alternativas' : 'Dissertativa/Aberta'}.
            
            REGRAS OBRIGAT√ìRIAS:
            1. Responda APENAS o objeto JSON puro.
            2. N√ÉO use markdown (como \`\`\`json).
            3. N√ÉO adicione texto antes ou depois do JSON.
            
            Estrutura do JSON de retorno:
            {
                "enunciado": "texto da quest√£o",
                "alternativas": ["A", "B", "C", "D"],
                "correta": 0, // √çndice da alternativa correta (0 a 3/4) - Apenas se m√∫ltipla escolha
                "gabarito": "resposta esperada ou explica√ß√£o"
            }
        `;

        let ultimoErro = "";

        // Loop de Tentativas (Fallback Strategy)
        for (let i = 0; i < this.MODELOS.length; i++) {
            const modelInfo = this.MODELOS[i];
            
            try {
                const url = `https://generativelanguage.googleapis.com/${modelInfo.v}/models/${modelInfo.id}:generateContent?key=${this.API_KEY}`;
                
                console.log(`ü§ñ Tentativa IA ${i + 1}/${this.MODELOS.length}: Usando ${modelInfo.id}...`);
                
                const response = await fetch(url, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        contents: [{ parts: [{ text: prompt }] }],
                        generationConfig: {
                            temperature: 0.7, // Criatividade controlada
                            topK: 40,
                            topP: 0.95,
                            maxOutputTokens: 1024,
                        }
                    })
                });

                const data = await response.json();

                // Tratamento de Erros da API
                if (!response.ok || data.error) {
                    const msg = data.error?.message || `Erro HTTP ${response.status}`;
                    console.warn(`‚ö†Ô∏è Modelo ${modelInfo.id} falhou: ${msg}`);
                    ultimoErro = msg;
                    
                    // Se for erro de limite (429), espera um pouco antes de tentar o pr√≥ximo
                    if (response.status === 429) await this._esperar(1000);
                    
                    throw new Error(msg); // For√ßa ir para o catch e tentar o pr√≥ximo loop
                }

                // Valida√ß√£o da Resposta
                if (!data.candidates?.[0]?.content?.parts?.[0]?.text) {
                    throw new Error("Resposta vazia da IA.");
                }

                const textResponse = data.candidates[0].content.parts[0].text;
                
                // Limpeza do JSON (caso a IA insista em markdown)
                const cleanJson = textResponse
                    .replace(/```json/gi, "")
                    .replace(/```/g, "")
                    .trim();

                const finalResult = JSON.parse(cleanJson);
                
                console.log(`‚úÖ Sucesso na gera√ß√£o com: ${modelInfo.id}`);
                return finalResult;

            } catch (error) {
                // Se foi a √∫ltima tentativa, lan√ßa o erro para o usu√°rio
                if (i === this.MODELOS.length - 1) {
                    console.error("‚ùå Falha cr√≠tica: Todos os modelos de IA falharam.");
                    throw new Error(`N√£o foi poss√≠vel gerar a quest√£o no momento. Tente novamente. Detalhe: ${ultimoErro || error.message}`);
                }
                // Se n√£o foi a √∫ltima, o loop continua e tenta o pr√≥ximo modelo
            }
        }
    }
};